{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q transformers datasets loralib sentencepiece bitsandbytes accelerate langchain torch torchvision torchaudio peft numpy protobuf jupyter ipykernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88502ef156644a3fb6b5ae3eeff538d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "일반적으로 내 이름은 고유명사입니다. 하지만 당신의 이름은 발음이 어렵거나 너무 흔하거나 하는 경우가 아니라면, 일반적으로 사용되는 이름입니다. 이름이 중요한 이유는 자신을 대표할 수 있는 것이기 때문입니다. \n",
      "\n",
      "또한, 외국인들은 보통 이름 대신 이니셜을 사용하기도 합니다. 그러나 한국에서는 인 \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import pipeline, AutoModelForCausalLM\n",
    "\n",
    "MODEL = 'beomi/KoAlpaca-Polyglot-5.8B'\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL,\n",
    "    torch_dtype=torch.float16,\n",
    "    low_cpu_mem_usage=True,\n",
    ").to(device=f\"cuda\", non_blocking=True)\n",
    "model.eval()\n",
    "\n",
    "pipe = pipeline(\n",
    "    'text-generation', \n",
    "    model=model,\n",
    "    tokenizer=MODEL,\n",
    "    device=0\n",
    ")\n",
    "\n",
    "def ask(x, context='', is_input_full=False):\n",
    "    ans = pipe(\n",
    "        f\"### 질문: {x}\\n\\n### 맥락: {context}\\n\\n### 답변:\" if context else f\"### 질문: {x}\\n\\n### 답변:\", \n",
    "        do_sample=True, \n",
    "        max_new_tokens=512,\n",
    "        temperature=0.7,\n",
    "        top_p=0.9,\n",
    "        return_full_text=False,\n",
    "        eos_token_id=2,\n",
    "    )\n",
    "    print(ans[0]['generated_text'])\n",
    "    \n",
    "ask('내 이름이 뭘까?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9dd9eda9a0945b895affadf7e75c804",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'intruction': 'What is the capital of England?', 'text': \"\\nUnderground, mainly because it is so cheap to live in London and Great Boston City centres reflect the rising emphasis on severely underdevelopmental state.\\nIf you address questions about what's the capital, please country us from within 60 hours.\\nWe deal not just that information is given, but rather that it is shared.\\nYou may keep this in mind for your visitor's or researchers' following-up working holiday.\\nThank you.\\n\\nComments:\\nForm Approachment Tips & Figures\\nTo obtain this information, please copy items/figures from within 30 hours; or paste them into existing provisions.\\nThe important thing is to keep the contact personally. Someone will assist you in the process.\\nExplorers may have more assistance than orders of clothing due to physical access, but it is not always suited.\\nNor do I encourage you to contact me again. Your cellular phone will contact you if you are still interested.\\n\\nSend me a message or make a call.\\nMy specialist web-officer is also a mailer and can assist you with all that’s mostly….\\n\\n### 답변:세계에서 가장 비싼 땅은 미국의 뉴욕시 맨하탄 지역입니다. 그러나 세계에서 생활비가 가장 많이 드는 도시는 영국의 런던입니다. 이유는 여러가지 요인이 있습니다. 먼저, 미국의 뉴욕시 맨하탄 지역은 물가가 비싸고 토지 임대료도 높기 때문에 생활비용이 매우 높습니다. 또한, 영국의 런던은 교통 시스템과 연결되어 있어 지리적 이점을 활용할 수 있으며, 패션이나 금융 등 다양한 산업이 발달해있어 고용 기회도 많습니다. 반면 프랑스 파리는 땅값이 싸지만, 건물 철거와 화재로 인해 치안이 불안정하고 음식과 호텔 비용이 매우 높습니다. 이 외에도 싱가포르, 홍콩, 일본 등도 매우 높은 집값과 생활비를 유지하고 있습니다. \"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'intruction': '내 이름이 뭘까?', 'text': ' What is your name?'}\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: 나의 이름은 전재형이야\n",
      "AI:\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " 내 이름은 John이야.\n",
      "\n",
      "This is my name, John. And this is my system.\n",
      "\n",
      "Listen, words in a sentence: \"Not everything you say is a good sign.\"\n",
      "\n",
      "With a hint of code: GPT-3 is very useful for our participation. Sometimes it's just a remark on the student's paper. Other times it can help to establish a functional baseboy.\n",
      "\n",
      "Someone: You are leaving at 7/7: Please stop asking questions!\n",
      "It's right on the page. Left yourself along with 'X'.\n",
      "\n",
      "Guess what?\n",
      "It's a powerful sixteen-year-old Bell Pepper. Thank you Miss Dad.\n",
      "\n",
      "(Pause)\n",
      "Another one: What sort of messaging app do you use in GPT-3?\n",
      "B: Not just English.\n",
      "M: For Children’s Parties, I love this one.\n",
      "It’s the best place to send me a message.\n",
      "\n",
      "### 응답: \"항상 저를 지지해주시는 여러분께 감사드립니다. 이번에는 다양한 언어로 대화하고자 합니다. 좋은 기회가 되시길 바랍니다.\"\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: 나의 이름은 전재형이야\n",
      "AI:  내 이름은 John이야.\n",
      "\n",
      "This is my name, John. And this is my system.\n",
      "\n",
      "Listen, words in a sentence: \"Not everything you say is a good sign.\"\n",
      "\n",
      "With a hint of code: GPT-3 is very useful for our participation. Sometimes it's just a remark on the student's paper. Other times it can help to establish a functional baseboy.\n",
      "\n",
      "Someone: You are leaving at 7/7: Please stop asking questions!\n",
      "It's right on the page. Left yourself along with 'X'.\n",
      "\n",
      "Guess what?\n",
      "It's a powerful sixteen-year-old Bell Pepper. Thank you Miss Dad.\n",
      "\n",
      "(Pause)\n",
      "Another one: What sort of messaging app do you use in GPT-3?\n",
      "B: Not just English.\n",
      "M: For Children’s Parties, I love this one.\n",
      "It’s the best place to send me a message.\n",
      "\n",
      "### 응답: \"항상 저를 지지해주시는 여러분께 감사드립니다. 이번에는 다양한 언어로 대화하고자 합니다. 좋은 기회가 되시길 바랍니다.\"\n",
      "Human: 니 이름은 뭐니?\n",
      "AI:\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " 제 이름은 John입니다.\n",
      "\n",
      "First name: Jack Robbins.\n",
      "Billy Robbins: ABC Robbins.\n",
      "\n",
      "Last name: XYZ Robbins.\n",
      "\n",
      "What is your name?\n",
      "John: 책을 읽고 있다고 해서 그냥 존이라고 불러요.\n",
      "\n",
      "Oh, I didn't know you were a Britney.\n",
      "\n",
      "You sure have changed a lot of things.\n",
      "\n",
      "Did you look forward to come out with all that change?\n",
      "An: 아니, 그런 건 없어. 그저 새로운 도전들이 신선할 뿐이야.\n",
      "\n",
      "It's nice to hear from you.\n",
      "\n",
      "A: 그래, 너한테 얘기하는 건 편하고 좋네.\n",
      "\n",
      "Thank you.\n",
      "\n",
      "B: 고맙습니다.\n",
      "\n",
      "여러분과 함께해서 정말 즐거웠어요.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: 나의 이름은 전재형이야\n",
      "AI:  내 이름은 John이야.\n",
      "\n",
      "This is my name, John. And this is my system.\n",
      "\n",
      "Listen, words in a sentence: \"Not everything you say is a good sign.\"\n",
      "\n",
      "With a hint of code: GPT-3 is very useful for our participation. Sometimes it's just a remark on the student's paper. Other times it can help to establish a functional baseboy.\n",
      "\n",
      "Someone: You are leaving at 7/7: Please stop asking questions!\n",
      "It's right on the page. Left yourself along with 'X'.\n",
      "\n",
      "Guess what?\n",
      "It's a powerful sixteen-year-old Bell Pepper. Thank you Miss Dad.\n",
      "\n",
      "(Pause)\n",
      "Another one: What sort of messaging app do you use in GPT-3?\n",
      "B: Not just English.\n",
      "M: For Children’s Parties, I love this one.\n",
      "It’s the best place to send me a message.\n",
      "\n",
      "### 응답: \"항상 저를 지지해주시는 여러분께 감사드립니다. 이번에는 다양한 언어로 대화하고자 합니다. 좋은 기회가 되시길 바랍니다.\"\n",
      "Human: 니 이름은 뭐니?\n",
      "AI:  제 이름은 John입니다.\n",
      "\n",
      "First name: Jack Robbins.\n",
      "Billy Robbins: ABC Robbins.\n",
      "\n",
      "Last name: XYZ Robbins.\n",
      "\n",
      "What is your name?\n",
      "John: 책을 읽고 있다고 해서 그냥 존이라고 불러요.\n",
      "\n",
      "Oh, I didn't know you were a Britney.\n",
      "\n",
      "You sure have changed a lot of things.\n",
      "\n",
      "Did you look forward to come out with all that change?\n",
      "An: 아니, 그런 건 없어. 그저 새로운 도전들이 신선할 뿐이야.\n",
      "\n",
      "It's nice to hear from you.\n",
      "\n",
      "A: 그래, 너한테 얘기하는 건 편하고 좋네.\n",
      "\n",
      "Thank you.\n",
      "\n",
      "B: 고맙습니다.\n",
      "\n",
      "여러분과 함께해서 정말 즐거웠어요.\n",
      "Human: 내 이름은 뭘까??\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " 아까 말했잖아.\n",
      "\n",
      "내 이름은 John이라고.\n",
      "\n",
      "이 이름은 옛날 위대한 개츠비에서 따온 거야.\n",
      "\n",
      "Frailty, thy name is what I cannot deal with.\n",
      "\n",
      "You have changed my life, and I can't accept it.\n",
      "\n",
      "In fact, I wanted to say goodbye to you, but I don't want to go through your personal life.\n",
      "\n",
      "Excrement! That's what I think of Mary.\n",
      "\n",
      "Oh, my darling, oh, my darling Oh, my darling Clementine You are leaving at noon; I can't say anything for some time.\n",
      "\n",
      "But I will wake up forever with a big smile.\n",
      "\n",
      "### 답변:\"클레멘타인\"이라는 노래는 미국 서부개척시대에 '포티나이너(forty-niner)'들이 슬픔을 달래기 위해 불렀던 노래입니다. 이들은 황금을 찾기 위해 캘리포니아의 광산으로 몰려들었지만 대부분이 열악한 조건 하에서 가혹한 노동과 혹독한 추위, 인디언의 습격 등에 시달렸습니다. 클레멘타인이란 딸이 있는 포티나이너에게 해당 노래는 상실의 노래였습니다. 이 노래를 부르면서 눈가에 눈물을 흘리며 일했던 것으로 유명합니다. 이 노래는 뮤지컬 형태로도 만들어졌으며, 미국인들의 가슴속에 오랫동안 기억되는 명곡 중 하나입니다. \n"
     ]
    }
   ],
   "source": [
    "from transformers import LlamaTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, pipeline\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.chains.conversation.memory import ConversationBufferWindowMemory\n",
    "import torch\n",
    "\n",
    "model_id = 'beomi/KoAlpaca-Polyglot-5.8B'\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    quantization_config=BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    ),\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "local_llm = HuggingFacePipeline(pipeline=pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=model_id,\n",
    "    max_length=10240,\n",
    "    do_sample=True,\n",
    "    temperature=0.7,\n",
    "    top_p=0.95,\n",
    "    repetition_penalty=1.2,\n",
    "    return_full_text=False,\n",
    "))\n",
    "\n",
    "llm_chain = LLMChain(\n",
    "    llm=local_llm,\n",
    "    prompt=PromptTemplate(input_variables=[\"instruction\"], template=\"### 질문:\\n{intruction}\\n\\n답변:\")\n",
    ")\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=local_llm,\n",
    "    verbose=True,\n",
    "    memory=ConversationBufferWindowMemory(k=4)\n",
    ")\n",
    "\n",
    "conversation.prompt.template = '''대화기록:\n",
    "{history}\n",
    "질문: {input}\n",
    "답변:'''\n",
    "\n",
    "def ask(question):\n",
    "    print(llm_chain.invoke(question))\n",
    "\n",
    "def chat(input):\n",
    "    print(conversation.predict(input=input))\n",
    "\n",
    "\n",
    "ask('What is the capital of England?')\n",
    "ask('내 이름이 뭘까?')\n",
    "chat('나의 이름은 전재형이야')\n",
    "chat('니 이름은 뭐니?')\n",
    "chat('내 이름은 뭘까??')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alpaca-with-langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
